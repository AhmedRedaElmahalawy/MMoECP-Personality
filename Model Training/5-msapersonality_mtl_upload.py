# -*- coding: utf-8 -*-
"""MSAPersonality-MTL-Upload.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JtZpFPRL3BJF1aEHq2HyH9-3uqjw5Yeg

CNN
"""

import time
import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_recall_curve

import tensorflow as tf
from keras import Sequential, Model, regularizers
from keras.layers import Dense, BatchNormalization, Dropout, Conv1D, MaxPooling1D, Flatten, Reshape
from keras.losses import Loss
from keras.metrics import BinaryAccuracy, AUC

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

traits = ['E', 'N', 'A', 'C', 'O']
y_all = data[traits].to_numpy(dtype=np.float32)

embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X_all = np.array(embeddings, dtype=np.float32)

num_tasks = y_all.shape[1]

# -----------------------------
# ONE split: 70/20/10
# -----------------------------
# 1) Split off TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X_all)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X_all)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X_all)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X_all)*100:.2f}%)")

# -----------------------------
# Threshold tuning (per label)
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        p, r, th = precision_recall_curve(y_true[:, i], y_prob[:, i])
        if th.size == 0:
            thresholds[i] = 0.5
            continue
        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]
    return thresholds

# -----------------------------
# Weighted BCE (computed once from TRAIN)
# -----------------------------
class MultiTaskWeightedBCE(Loss):
    """
    Weighted BCE on probabilities (NOT logits).
    pos_weight_vec shape: (num_tasks,)
    """
    def __init__(self, pos_weight_vec):
        super().__init__()
        self.pos_weight = tf.reshape(tf.cast(pos_weight_vec, tf.float32), (1, -1))

    def call(self, y_true, y_pred):
        y_true = tf.cast(y_true, tf.float32)
        y_pred = tf.clip_by_value(y_pred, 1e-7, 1. - 1e-7)

        pos_term = - self.pos_weight * y_true * tf.math.log(y_pred)
        neg_term = - (1. - y_true) * tf.math.log(1. - y_pred)

        # sum over tasks, mean over batch
        return tf.reduce_mean(tf.reduce_sum(pos_term + neg_term, axis=1))

# -----------------------------
# CNN block
# -----------------------------
class CNN(Sequential):
    def __init__(self,
                 num_conv_layers: int,
                 filters: int,
                 kernel_size: int,
                 pool_size: int,
                 dense_units: int,
                 dim_out: int = None,
                 dropout: float = 0.0,
                 l2: float = 1e-4,
                 name: str = "CNN"):
        layers = []
        layers.append(Reshape((-1, 1)))  # (bs, D) -> (bs, D, 1)

        for _ in range(num_conv_layers):
            layers.append(Conv1D(filters=filters,
                                 kernel_size=kernel_size,
                                 activation='relu',
                                 kernel_regularizer=regularizers.l2(l2)))
            layers.append(MaxPooling1D(pool_size=pool_size))
            layers.append(BatchNormalization())

        layers.append(Flatten())

        if dense_units:
            layers.append(Dense(dense_units, activation='relu',
                                kernel_regularizer=regularizers.l2(l2)))

        if dropout > 0.0:
            layers.append(Dropout(dropout))

        if dim_out:
            layers.append(Dense(dim_out))  # logits

        super().__init__(layers, name=name)

# -----------------------------
# MG-MoE with CNN experts/towers
# -----------------------------
class MultiGateMixtureOfExperts(Model):
    def __init__(self,
                 num_tasks: int,
                 num_emb: int,
                 num_experts: int = 3,

                 num_conv_layers_expert: int = 3,
                 filters_expert: int = 64,
                 kernel_size_expert: int = 3,
                 pool_size_expert: int = 2,
                 dense_units_expert: int = 64,
                 dropout_expert: float = 0.1,
                 l2_expert: float = 1e-3,

                 gate_function: str = "softmax",

                 num_conv_layers_tasks: int = 2,
                 filters_tasks: int = 64,
                 kernel_size_tasks: int = 3,
                 pool_size_tasks: int = 2,
                 dense_units_tasks: int = 64,
                 dim_out_tasks: int = 1,
                 dropout_tasks: float = 0.1,
                 l2_tasks: float = 1e-3):
        super().__init__()

        self.experts = [
            CNN(num_conv_layers_expert, filters_expert, kernel_size_expert, pool_size_expert,
                dense_units_expert, dropout=dropout_expert, l2=l2_expert, name=f"expert_{i}")
            for i in range(num_experts)
        ]

        self.towers = [
            CNN(num_conv_layers_tasks, filters_tasks, kernel_size_tasks, pool_size_tasks,
                dense_units_tasks, dim_out_tasks, dropout=dropout_tasks, l2=l2_tasks, name=f"tower_{t}")
            for t in range(num_tasks)
        ]

        self.gates = [
            Dense(num_experts, activation=gate_function, use_bias=False, name=f"gate_{t}")
            for t in range(num_tasks)
        ]

    def call(self, inputs: tf.Tensor, training: bool = None) -> tf.Tensor:
        # Experts: (bs, D) -> (bs, H) for each expert
        out_experts = []
        expert_input = tf.expand_dims(inputs, -1)  # (bs, D, 1)
        for expert in self.experts:
            out_experts.append(expert(expert_input, training=training))  # (bs, H)

        out_experts = tf.stack(out_experts, axis=-1)  # (bs, H, E)

        # Tasks
        out_tasks = []
        for gate, tower in zip(self.gates, self.towers):
            gate_score = gate(inputs, training=training)              # (bs, E)
            mixed = tf.einsum("bhe,be->bh", out_experts, gate_score)  # (bs, H)
            logits = tower(tf.expand_dims(mixed, -1), training=training)  # (bs, 1)
            out_tasks.append(logits)

        out = tf.concat(out_tasks, axis=-1)  # (bs, num_tasks) logits
        return tf.nn.sigmoid(out)            # probabilities

# -----------------------------
# Training (ONE run)
# -----------------------------
epochs = 60
batch_size = 64

# pos_weight from TRAIN only
eps = 1e-8
pos_counts = np.sum(y_train, axis=0)
neg_counts = y_train.shape[0] - pos_counts
pos_weight = (neg_counts + eps) / (pos_counts + eps)   # (num_tasks,)
pos_weight_tf = tf.constant(pos_weight, dtype=tf.float32)

print("pos_weight (from TRAIN):", dict(zip(traits, np.round(pos_weight, 4))))

# Fresh model
tf.keras.backend.clear_session()
tf.random.set_seed(GLOBAL_SEED)
np.random.seed(GLOBAL_SEED)

num_embeddings = X_train.shape[1]

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    num_emb=num_embeddings,
    num_experts=3,

    num_conv_layers_expert=3, filters_expert=64, kernel_size_expert=3, pool_size_expert=2,
    dense_units_expert=64, dropout_expert=0.1, l2_expert=1e-4,

    gate_function="softmax",

    num_conv_layers_tasks=2, filters_tasks=64, kernel_size_tasks=3, pool_size_tasks=2,
    dense_units_tasks=64, dim_out_tasks=1, dropout_tasks=0.1, l2_tasks=1e-4
)

loss = MultiTaskWeightedBCE(pos_weight_tf)
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

model.compile(
    optimizer=optimizer,
    loss=loss,
    metrics=[
        BinaryAccuracy(name="bin_acc"),
        AUC(name="auc", multi_label=True)
    ]
)

early_stop = tf.keras.callbacks.EarlyStopping(
    monitor="val_auc", mode="max", patience=7, restore_best_weights=True
)
reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(
    monitor="val_auc", mode="max", factor=0.6, patience=3, min_lr=1e-6, verbose=1
)

start = time.process_time()

model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=epochs,
    batch_size=batch_size,
    callbacks=[early_stop, reduce_lr],
    verbose=2
)

elapsed_cpu = time.process_time() - start

# -----------------------------
# Threshold tuning on VAL
# -----------------------------
y_val_prob = model.predict(X_val, verbose=0)
thr = best_thresholds(y_val, y_val_prob)
# -----------------------------
# Evaluate on TEST
# -----------------------------
y_test_prob = model.predict(X_test, verbose=0)
y_pred_labels = (y_test_prob >= thr).astype(int)

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i, name in enumerate(traits):
    f1_i = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {name} - F1: {f1_i:.2f}")

print(f"\nCPU time (train only): {elapsed_cpu:.2f} s")

"""MMLP"""

import time
import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import f1_score, precision_recall_curve

import tensorflow as tf
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras import Sequential

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load and preprocess the data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

# Load the saved BERT embeddings
embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X_all = np.array(embeddings, dtype=np.float32)

# Labels
traits = ['E', 'N', 'A', 'C', 'O']
y_all = data[traits].to_numpy()

# Ensure binary labels (keeps 0/1; maps -1->0; thresholds floats)
if np.any(y_all == -1):
    y_all = np.where(y_all == -1, 0, y_all)
y_all = (y_all >= 0.5).astype(np.int32)

num_tasks = y_all.shape[1]

# -----------------------------
# ONE split: 70/20/10
# -----------------------------
# 1) Split off TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full data => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X_all)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X_all)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X_all)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X_all)*100:.2f}%)")

# -----------------------------
# Per-label threshold tuning (safe)
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        yt = y_true[:, i].astype(int)
        yp = y_prob[:, i].astype(float)

        # If only one class in validation split, PR curve undefined
        if len(np.unique(yt)) < 2:
            thresholds[i] = 0.5
            continue

        p, r, th = precision_recall_curve(yt, yp)
        if th.size == 0:
            thresholds[i] = 0.5
            continue

        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]

    return thresholds

# -----------------------------
# Updated MLP Expert (sklearn)
# -----------------------------
class MLPExpert:
    def __init__(self,
                 hidden_layer_sizes=(200,),
                 max_iter=200,
                 activation='relu',
                 solver='adam',
                 alpha=0.0001,
                 learning_rate_init=0.01,
                 seed=42):
        self.model = MLPClassifier(
            random_state=seed,
            hidden_layer_sizes=hidden_layer_sizes,
            max_iter=max_iter,
            activation=activation,
            solver=solver,
            alpha=alpha,
            learning_rate_init=learning_rate_init
        )

    def train(self, X_train, y_train_1d):
        self.model.fit(X_train, y_train_1d)

    def predict_proba_pos(self, X):
        proba = self.model.predict_proba(X)
        # If only one class present in training split, sklearn returns (n,1)
        if proba.shape[1] == 1:
            cls = self.model.classes_[0]
            return np.ones((X.shape[0],), dtype=np.float32) if cls == 1 else np.zeros((X.shape[0],), dtype=np.float32)
        return proba[:, 1].astype(np.float32)

# -----------------------------
# MGMOE (gates not trained; random)
# -----------------------------
class MultiGateMixtureOfExperts:
    """
    NOTE: This matches your original behavior:
    - Experts are trained (but see note below).
    - Gates are NOT trained (no optimizer/fit), so they stay random.
    """
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 3, seed: int = 42):
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [MLPExpert(seed=seed) for _ in range(num_experts)]

        tf.random.set_seed(seed)
        self.gates = [
            Sequential([
                Dense(num_experts, activation='softmax', input_shape=(input_dim,)),
                Dropout(0.2)
            ])
            for _ in range(num_tasks)
        ]

    def train_experts(self, X_train, y_train):
        # WARNING: this trains expert i on task i (works best when num_experts == num_tasks)
        # Keeping it exactly like your original script.
        for i in range(self.num_experts):
            self.experts[i].train(X_train, y_train[:, i])

    def predict(self, X):
        out_experts = np.stack(
            [expert.predict_proba_pos(X) for expert in self.experts],
            axis=-1
        )  # (bs, E)

        out_tasks = []
        for gate in self.gates:
            gate_scores = gate(X, training=False).numpy().astype(np.float32)   # (bs, E)
            task_output = np.sum(out_experts * gate_scores, axis=-1)           # (bs,)
            out_tasks.append(task_output)

        return np.stack(out_tasks, axis=-1).astype(np.float32)  # (bs, T)

# -----------------------------
# Train once (ONE run)
# -----------------------------
start = time.process_time()

# Fresh seeds
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=3,
    seed=GLOBAL_SEED
)
model.train_experts(X_train, y_train)

# -----------------------------
# Threshold tuning on VAL
# -----------------------------
y_val_prob = model.predict(X_val)
thr = best_thresholds(y_val, y_val_prob)
print("Per-label thresholds:", dict(zip(traits, np.round(thr, 4))))

# -----------------------------
# Evaluate on TEST
# -----------------------------
y_test_prob = model.predict(X_test)
y_pred_labels = (y_test_prob >= 0.3).astype(int)

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i, name in enumerate(traits):
    f1_i = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {name} - F1: {f1_i:.2f}")

elapsed_cpu = time.process_time() - start
print(f"\nCPU time: {elapsed_cpu:.2f} s")

"""BERT"""

import time
import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_recall_curve

import tensorflow as tf
from keras import Sequential, Model
from keras.layers import Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D
from keras.losses import Loss, binary_crossentropy
from keras.metrics import Accuracy

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X = np.array(embeddings, dtype=np.float32)

traits = ['E', 'N', 'A', 'C', 'O']
y = data[traits].to_numpy(dtype=np.float32)

num_tasks = y.shape[1]

# -----------------------------
# ONE split: 70/20/10
# -----------------------------
# 1) Split off TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X)*100:.2f}%)")

# -----------------------------
# Loss Function
# -----------------------------
class MultiTaskBCE(Loss):
    def __init__(self, num_tasks: int, task_weights=None) -> None:
        super().__init__()
        if task_weights is None:
            self.task_weights = tf.ones((1, num_tasks))
        elif tf.rank(task_weights) == 1:
            self.task_weights = tf.expand_dims(task_weights, 0)
        else:
            self.task_weights = task_weights

    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
        bce = binary_crossentropy(y_true, y_pred)           # (batch, tasks)
        loss = self.task_weights * tf.reduce_mean(bce, axis=0)
        return tf.reduce_sum(loss)

# -----------------------------
# Model blocks
# -----------------------------
class TransformerBlock(Model):
    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.01):
        super().__init__()
        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = Sequential([
            Dense(ff_dim, activation="relu"),
            Dense(embed_dim),
        ])
        self.layernorm1 = LayerNormalization(epsilon=1e-2)
        self.layernorm2 = LayerNormalization(epsilon=1e-2)
        self.dropout1 = Dropout(rate)
        self.dropout2 = Dropout(rate)

    def call(self, inputs, training=False):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class ExpertTransformer(Model):
    def __init__(self, embed_dim, num_heads, ff_dim, dropout_rate=0.1):
        super().__init__()
        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim, dropout_rate)
        self.pool = GlobalAveragePooling1D()
        self.dense = Dense(ff_dim, activation="relu")
        self.dropout = Dropout(dropout_rate)

    def call(self, inputs, training=False):
        x = tf.expand_dims(inputs, 1)  # (batch, seq=1, embed_dim)
        x = self.transformer_block(x, training=training)
        x = self.pool(x)
        x = self.dense(x)
        x = self.dropout(x, training=training)
        return x

class MultiGateMixtureOfExperts(Model):
    def __init__(self, num_tasks: int, embed_dim: int, num_experts: int = 3,
                 num_heads: int = 8, ff_dim: int = 64, dropout_rate: float = 0.01):
        super().__init__()
        self.experts = [ExpertTransformer(embed_dim, num_heads, ff_dim, dropout_rate)
                        for _ in range(num_experts)]
        self.gates = [Dense(num_experts, activation="softmax", use_bias=False)
                      for _ in range(num_tasks)]
        self.towers = [Sequential([
            Dense(64, activation="relu"),
            Dropout(dropout_rate),
            Dense(1)
        ]) for _ in range(num_tasks)]

    def call(self, inputs, training=False):
        expert_outputs = [expert(inputs, training=training) for expert in self.experts]
        expert_outputs = tf.stack(expert_outputs, axis=1)  # (batch, num_experts, hidden_dim)

        task_outputs = []
        for gate, tower in zip(self.gates, self.towers):
            gate_scores = gate(inputs)                       # (batch, num_experts)
            mixed_expert = tf.einsum('bnd,bn->bd', expert_outputs, gate_scores)
            output = tower(mixed_expert, training=training)  # (batch, 1)
            task_outputs.append(output)

        out = tf.concat(task_outputs, axis=-1)              # (batch, num_tasks)
        return tf.nn.sigmoid(out)

# -----------------------------
# Per-label threshold tuning
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        p, r, th = precision_recall_curve(y_true[:, i], y_prob[:, i])
        if th.size == 0:
            thresholds[i] = 0.5
            continue
        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]
    return thresholds

# -----------------------------
# Train once (ONE run)
# -----------------------------
num_tasks = 5
epochs = 5
batch_size = 32

tf.keras.backend.clear_session()
tf.random.set_seed(GLOBAL_SEED)
np.random.seed(GLOBAL_SEED)

embed_dim = X_train.shape[1]
model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    embed_dim=embed_dim,
    num_experts=3,
    num_heads=8,
    ff_dim=64,
    dropout_rate=0.01
)

loss = MultiTaskBCE(num_tasks=num_tasks)
optimizer = tf.keras.optimizers.Adam()

model.compile(optimizer=optimizer, loss=loss, metrics=[Accuracy()])

start = time.process_time()

model.fit(
    X_train, y_train,
    validation_data=(X_val, y_val),
    epochs=epochs,
    batch_size=batch_size,
    verbose=1
)

elapsed_cpu = time.process_time() - start

# -----------------------------
# Threshold tuning on VAL
# -----------------------------
y_val_prob = model.predict(X_val, verbose=0)
thr = best_thresholds(y_val, y_val_prob)

# -----------------------------
# Evaluate on TEST
# -----------------------------
y_test_prob = model.predict(X_test, verbose=0)
y_pred_labels = (y_test_prob >= thr).astype(int)

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i in range(num_tasks):
    f1_task = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {traits[i]} - F1: {f1_task:.2f}")

print(f"\nCPU time (train only): {elapsed_cpu:.2f} s")

"""LR"""

import numpy as np
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
import tensorflow as tf
from keras.losses import Loss, binary_crossentropy
from sklearn.metrics import f1_score
import time

# ----------------------------
# Reproducibility
# ----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# ----------------------------
# Load and preprocess the data
# ----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

labels = data[['E', 'N', 'A', 'C', 'O']]

embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X = np.array(embeddings, dtype=np.float32)

y = np.column_stack((
    labels['E'].to_numpy(dtype=np.int32),
    labels['N'].to_numpy(dtype=np.int32),
    labels['A'].to_numpy(dtype=np.int32),
    labels['C'].to_numpy(dtype=np.int32),
    labels['O'].to_numpy(dtype=np.int32),
))

num_tasks = 5
num_experts = 3
labels_name = ['cEXT1', 'cNEU1', 'cAGR1', 'cCON1', 'cOPN1']

epochs = 30
batch_size = 32

# ----------------------------
# 70/20/10 split (ONE time)
# ----------------------------
# Step 1: split off TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# Step 2: split TRAIN/VAL from remaining 90%
# VAL should be 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X)*100:.2f}%)")

# ----------------------------
# Loss Function
# ----------------------------
class MultiTaskBCE(Loss):
    def __init__(self, num_tasks: int, task_weights=None) -> None:
        super().__init__()
        if task_weights is None:
            self.task_weights = tf.ones((1, num_tasks))
        elif tf.rank(task_weights) == 1:
            self.task_weights = tf.expand_dims(task_weights, 0)
        else:
            self.task_weights = task_weights

    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:
        # Reduce over hidden-expert dimension -> (bs, num_tasks)
        y_pred_reduced = tf.reduce_mean(y_pred, axis=1)
        bce = binary_crossentropy(y_true, y_pred_reduced)
        loss = self.task_weights * tf.reduce_mean(bce, axis=0)
        return tf.reduce_sum(loss)

# ----------------------------
# Logistic Regression Expert (simple linear layer)
# ----------------------------
class LogisticRegression(tf.Module):
    def __init__(self):
        super().__init__()
        self.built = False

    def __call__(self, x, train=True):
        x = tf.convert_to_tensor(x, dtype=tf.float32)

        if not self.built:
            rand_w = tf.random.uniform(shape=[x.shape[-1], 1], seed=22)
            rand_b = tf.random.uniform(shape=[], seed=22)
            self.w = tf.Variable(rand_w)
            self.b = tf.Variable(rand_b)
            self.built = True

        z = tf.add(tf.matmul(x, self.w), self.b)
        z = tf.squeeze(z, axis=1)

        if train:
            return z
        return tf.sigmoid(z)

# ----------------------------
# MGMOE Model with Logistic Regression Experts
# ----------------------------
class MultiGateMixtureOfExperts(tf.Module):
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 3, gate_function: str = "softmax"):
        super().__init__()
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [LogisticRegression() for _ in range(num_experts)]
        self.gates = [
            tf.Variable(tf.random.uniform([input_dim, num_experts], seed=GLOBAL_SEED), trainable=True)
            for _ in range(num_tasks)
        ]

    def __call__(self, inputs: tf.Tensor, train=True):
        inputs = tf.convert_to_tensor(inputs, dtype=tf.float32)

        # (bs, num_experts) because each expert returns (bs,)
        out_experts = tf.stack([expert(inputs, train=train) for expert in self.experts], axis=-1)

        out_tasks = []
        for gate in self.gates:
            gate_scores = tf.nn.softmax(tf.matmul(inputs, gate), axis=-1)      # (bs, num_experts)
            task_output = tf.reduce_sum(out_experts * gate_scores, axis=-1)    # (bs,)
            out_tasks.append(task_output)

        # (bs, num_tasks) then expand to (bs, 1, num_tasks) to match your loss
        out = tf.stack(out_tasks, axis=-1)           # (bs, num_tasks)
        out = tf.expand_dims(out, axis=1)            # (bs, 1, num_tasks)

        if not train:
            out = tf.sigmoid(out)
        return out

# ----------------------------
# Training step
# ----------------------------
@tf.function
def train_step(model, inputs, labels, loss_fn, optimizer):
    with tf.GradientTape() as tape:
        predictions = model(inputs, train=True)
        loss = loss_fn(labels, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    return loss

# ----------------------------
# Train (ONE run)
# ----------------------------
tf.random.set_seed(GLOBAL_SEED)
model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=num_experts,
    gate_function="softmax"
)
loss_fn = MultiTaskBCE(num_tasks=num_tasks)
optimizer = tf.keras.optimizers.Adam()

start = time.process_time()

num_batches = int(np.ceil(X_train.shape[0] / batch_size))

for epoch in range(epochs):
    epoch_loss = 0.0

    # Shuffle each epoch
    idx = np.random.permutation(X_train.shape[0])
    X_train_shuf = X_train[idx]
    y_train_shuf = y_train[idx]

    for i in range(num_batches):
        batch_x = X_train_shuf[i*batch_size:(i+1)*batch_size]
        batch_y = y_train_shuf[i*batch_size:(i+1)*batch_size]
        batch_loss = train_step(model, batch_x, batch_y, loss_fn, optimizer)
        epoch_loss += float(batch_loss.numpy())

    print(f"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss:.4f}")

elapsed_cpu = time.process_time() - start

# ----------------------------
# Evaluate on VAL + TEST
# ----------------------------
def evaluate_split(split_name, X_split, y_split):
    y_pred = model(X_split, train=False)             # (n, 1, T) sigmoid already applied
    y_pred = tf.reduce_mean(y_pred, axis=1)          # (n, T)
    y_pred_labels = (y_pred.numpy() > 0.5).astype(int)

    f1_micro = f1_score(y_split, y_pred_labels, average='micro', zero_division=0) * 100
    f1_macro = f1_score(y_split, y_pred_labels, average='macro', zero_division=0) * 100

    print(f"\n[{split_name}] F1-micro: {f1_micro:.2f}")
    print(f"[{split_name}] F1-macro: {f1_macro:.2f}")
    for i in range(num_tasks):
        f1_task = f1_score(y_split[:, i], y_pred_labels[:, i], zero_division=0) * 100
        print(f"  Task {labels_name[i]} - F1: {f1_task:.2f}")

evaluate_split("TEST", X_test, y_test)

print(f"\nCPU time (train only): {elapsed_cpu:.2f} s")

"""XGB"""

import numpy as np
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score, precision_recall_curve
import tensorflow as tf
from xgboost import XGBClassifier
import time

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

traits = ['E', 'N', 'A', 'C', 'O']
labels = data[traits]

embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X_all = np.array(embeddings, dtype=np.float32)

y_all = np.column_stack([
    labels['E'], labels['N'], labels['A'], labels['C'], labels['O']
]).astype(np.int32)

# Replace -1 with 0 (if exists)
y_all = np.where(y_all == -1, 0, y_all)

num_tasks = y_all.shape[1]
labels_name = traits

# -----------------------------
# ONE split: 70/20/10 (no folds)
# -----------------------------
# 1) TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X_all)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X_all)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X_all)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X_all)*100:.2f}%)")

# -----------------------------
# Per-label threshold tuning (VAL)
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        yt = y_true[:, i].astype(int)
        yp = y_prob[:, i].astype(float)

        # If only one class in validation, PR curve undefined
        if len(np.unique(yt)) < 2:
            thresholds[i] = 0.5
            continue

        p, r, th = precision_recall_curve(yt, yp)
        if th.size == 0:
            thresholds[i] = 0.5
            continue

        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]
    return thresholds

# ----------------------------
# XGBClassifier Expert
# ----------------------------
class XGBExpert:
    def __init__(self, seed=42):
        self.model = XGBClassifier(
            n_estimators=100,
            max_depth=2,
            learning_rate=0.1,
            objective='binary:logistic',
            eval_metric='logloss',
            random_state=seed,
            n_jobs=-1
        )

    def train(self, X_train, y_train_1d):
        self.model.fit(X_train, y_train_1d)

    def predict_proba_pos(self, X):
        proba = self.model.predict_proba(X)
        # handle rare single-class issues
        if proba.shape[1] == 1:
            # XGBoost normally returns 2 columns, but keep safe anyway
            return np.zeros((X.shape[0],), dtype=np.float32)
        return proba[:, 1].astype(np.float32)

# ----------------------------
# MGMOE (random gates, not trained)
# ----------------------------
class MultiGateMixtureOfExperts:
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 3, seed: int = 42):
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [XGBExpert(seed=seed) for _ in range(num_experts)]
        self.gates = [
            tf.Variable(tf.random.uniform([input_dim, num_experts], seed=seed), trainable=True)
            for _ in range(num_tasks)
        ]

    def train_experts(self, X_train, y_train):
        # NOTE: trains expert i on task i (same pattern as your other scripts)
        for i in range(self.num_experts):
            self.experts[i].train(X_train, y_train[:, i])

    def predict(self, X):
        out_experts = np.stack(
            [expert.predict_proba_pos(X) for expert in self.experts],
            axis=-1
        )  # (n, E)

        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)

        out_tasks = []
        for gate in self.gates:
            gate_scores = tf.nn.softmax(tf.matmul(X_tf, gate), axis=-1).numpy().astype(np.float32)  # (n, E)
            task_output = np.sum(out_experts * gate_scores, axis=-1).astype(np.float32)             # (n,)
            out_tasks.append(task_output)

        return np.stack(out_tasks, axis=-1).astype(np.float32)  # (n, T)

# ----------------------------
# Train once (no folds)
# ----------------------------
num_experts = 3
start = time.process_time()

np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=num_experts,
    seed=GLOBAL_SEED
)
model.train_experts(X_train, y_train)

# ----------------------------
# Threshold tuning on VAL
# ----------------------------
y_val_prob = model.predict(X_val)
thr = best_thresholds(y_val, y_val_prob)

# ----------------------------
# Evaluate on TEST
# ----------------------------
y_test_prob = model.predict(X_test)
y_pred_labels = (y_test_prob >= 0.12).astype(np.int32)

assert y_test.shape == y_pred_labels.shape

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro (sklearn): {f1_micro:.2f}")
print(f"F1-macro (sklearn): {f1_macro:.2f}")

for i in range(num_tasks):
    f1_task = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {labels_name[i]} - F1: {f1_task:.2f}")

elapsed_cpu = time.process_time() - start
print(f"\nCPU time: {elapsed_cpu:.2f} s")

"""RF"""

import time
import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import f1_score, precision_recall_curve
import tensorflow as tf

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load and preprocess the data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

# Load the saved BERT embeddings
embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X_all = np.array(embeddings, dtype=np.float32)

# Labels
traits = ['E', 'N', 'A', 'C', 'O']
y_all = data[traits].to_numpy()

# Ensure binary labels (keeps 0/1; maps -1->0; thresholds floats)
if np.any(y_all == -1):
    y_all = np.where(y_all == -1, 0, y_all)
y_all = (y_all >= 0.5).astype(np.int32)

num_tasks = y_all.shape[1]
labels_name = traits

# -----------------------------
# ONE split: 70/20/10 (no folds)
# -----------------------------
# 1) TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X_all)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X_all)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X_all)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X_all)*100:.2f}%)")

# -----------------------------
# Per-label threshold tuning (safe)
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        yt = y_true[:, i].astype(int)
        yp = y_prob[:, i].astype(float)

        # If only one class in validation split, PR curve undefined
        if len(np.unique(yt)) < 2:
            thresholds[i] = 0.5
            continue

        p, r, th = precision_recall_curve(yt, yp)
        if th.size == 0:
            thresholds[i] = 0.5
            continue

        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]
    return thresholds

# -----------------------------
# RandomForest Expert (sklearn)
# -----------------------------
class RandomForestExpert:
    def __init__(self,
                 num_trees=300,
                 max_depth=7,
                 min_samples_split=3,
                 min_samples_leaf=2,
                 max_features='log2',
                 ccp_alpha=0.01,
                 criterion='entropy',
                 seed=100):
        self.model = RandomForestClassifier(
            n_estimators=num_trees,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            max_features=max_features,
            random_state=seed,
            n_jobs=-1,
            ccp_alpha=ccp_alpha,
            criterion=criterion
        )

    def train(self, X_train, y_train_1d):
        self.model.fit(X_train, y_train_1d)

    def predict_proba_pos(self, X):
        proba = self.model.predict_proba(X)
        # If only one class present in training split, sklearn returns (n,1)
        if proba.shape[1] == 1:
            cls = self.model.classes_[0]
            return np.ones((X.shape[0],), dtype=np.float32) if cls == 1 else np.zeros((X.shape[0],), dtype=np.float32)
        return proba[:, 1].astype(np.float32)

# -----------------------------
# MGMOE (gates not trained; random)
# -----------------------------
class MultiGateMixtureOfExperts:
    """
    Matches your earlier MGMOE scripts:
    - Experts are trained.
    - Gates are NOT trained (no optimizer/fit), so mixtures are random.
    """
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 4, seed: int = 42):
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [RandomForestExpert(seed=100) for _ in range(num_experts)]
        self.gates = [
            tf.Variable(tf.random.uniform([input_dim, num_experts], seed=seed), trainable=True)
            for _ in range(num_tasks)
        ]

    def train_experts(self, X_train, y_train):
        # WARNING: trains expert i on task i (works best when num_experts == num_tasks)
        # Keeping your original behavior.
        for i in range(self.num_experts):
            self.experts[i].train(X_train, y_train[:, i])

    def predict(self, X):
        out_experts = np.stack(
            [expert.predict_proba_pos(X) for expert in self.experts],
            axis=-1
        )  # (n, E)

        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)

        out_tasks = []
        for gate in self.gates:
            gate_scores = tf.nn.softmax(tf.matmul(X_tf, gate), axis=-1).numpy().astype(np.float32)  # (n, E)
            task_output = np.sum(out_experts * gate_scores, axis=-1).astype(np.float32)             # (n,)
            out_tasks.append(task_output)

        return np.stack(out_tasks, axis=-1).astype(np.float32)  # (n, T)

# -----------------------------
# Train once (no folds)
# -----------------------------
num_experts = 4

start = time.process_time()

np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=num_experts,
    seed=GLOBAL_SEED
)
model.train_experts(X_train, y_train)

# -----------------------------
# Threshold tuning on VAL
# -----------------------------
y_val_prob = model.predict(X_val)
thr = best_thresholds(y_val, y_val_prob)
print("Per-label thresholds:", dict(zip(traits, np.round(thr, 4))))

# -----------------------------
# Evaluate on TEST
# -----------------------------
y_test_prob = model.predict(X_test)
y_pred_labels = (y_test_prob >= 0.3).astype(np.int32)

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i, name in enumerate(labels_name):
    f1_i = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {name} - F1: {f1_i:.2f}")

# Optional: manual micro F1 check
tp = fp = fn = 0
for i in range(num_tasks):
    tp += np.sum((y_test[:, i] == 1) & (y_pred_labels[:, i] == 1))
    fp += np.sum((y_test[:, i] == 0) & (y_pred_labels[:, i] == 1))
    fn += np.sum((y_test[:, i] == 1) & (y_pred_labels[:, i] == 0))

precision_micro_manual = tp / (tp + fp) if (tp + fp) > 0 else 0
recall_micro_manual = tp / (tp + fn) if (tp + fn) > 0 else 0
f1_micro_manual = (
    2 * precision_micro_manual * recall_micro_manual / (precision_micro_manual + recall_micro_manual)
    if (precision_micro_manual + recall_micro_manual) > 0 else 0
)
print(f"\nManual F1-micro: {f1_micro_manual*100:.2f}")

elapsed_cpu = time.process_time() - start
print(f"\nCPU time: {elapsed_cpu:.2f} s")

"""DT"""

import numpy as np
import pandas as pd
import joblib
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
import tensorflow as tf
import time

# ----------------------------
# Reproducibility
# ----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# ----------------------------
# Load and preprocess the data
# ----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

labels = data[['E', 'N', 'A', 'C', 'O']].to_numpy(dtype=np.int32)

# Load the saved BERT embeddings (CORRECT FILE)
embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X = np.array(embeddings, dtype=np.float32)

y = labels
num_tasks = y.shape[1]
labels_name = ['E', 'N', 'A', 'C', 'O']

# ----------------------------
# ONE split: 70 / 20 / 10
# ----------------------------
# 1) Test = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X, y,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) Val = 20% of full â†’ 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X)*100:.2f}%)")

# ----------------------------
# Decision Tree Expert
# ----------------------------
class DecisionTreeExpert:
    def __init__(self,
                 criterion='log_loss',
                 splitter='best',
                 max_depth=8,
                 min_samples_split=2,
                 min_samples_leaf=1,
                 random_state=42,
                 ccp_alpha=0.1):
        self.model = DecisionTreeClassifier(
            criterion=criterion,
            splitter=splitter,
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            min_samples_leaf=min_samples_leaf,
            random_state=random_state,
            ccp_alpha=ccp_alpha
        )

    def train(self, X_train, y_train_1d):
        self.model.fit(X_train, y_train_1d)

    def predict_proba_pos(self, X):
        proba = self.model.predict_proba(X)
        # Handle single-class edge case
        if proba.shape[1] == 1:
            cls = self.model.classes_[0]
            return np.ones((X.shape[0],), dtype=np.float32) if cls == 1 else np.zeros((X.shape[0],), dtype=np.float32)
        return proba[:, 1].astype(np.float32)

# ----------------------------
# MGMOE (random, untrained gates)
# ----------------------------
class MultiGateMixtureOfExperts:
    """
    Same behavior as your original code:
    - Experts are trained
    - Gates are random and NOT optimized
    """
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 3, seed: int = 42):
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [DecisionTreeExpert(random_state=seed) for _ in range(num_experts)]
        self.gates = [
            tf.Variable(tf.random.uniform([input_dim, num_experts], seed=seed), trainable=True)
            for _ in range(num_tasks)
        ]

    def train_experts(self, X_train, y_train):
        # NOTE: expert i is trained on task i (same as your original)
        for i in range(self.num_experts):
            self.experts[i].train(X_train, y_train[:, i])

    def predict(self, X):
        out_experts = np.stack(
            [expert.predict_proba_pos(X) for expert in self.experts],
            axis=-1
        )  # (n, E)

        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)

        out_tasks = []
        for gate in self.gates:
            gate_scores = tf.nn.softmax(tf.matmul(X_tf, gate), axis=-1).numpy()
            task_output = np.sum(out_experts * gate_scores, axis=-1)
            out_tasks.append(task_output)

        return np.stack(out_tasks, axis=-1)  # (n, T)

# ----------------------------
# Train ONCE
# ----------------------------
start = time.process_time()

tf.random.set_seed(GLOBAL_SEED)
np.random.seed(GLOBAL_SEED)

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=3,
    seed=GLOBAL_SEED
)

model.train_experts(X_train, y_train)

# ----------------------------
# Evaluate on TEST
# ----------------------------
y_pred = model.predict(X_test)
y_pred_labels = (y_pred > 0.18).astype(int)

assert y_test.shape == y_pred_labels.shape

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i in range(num_tasks):
    f1_task = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {labels_name[i]} - F1: {f1_task:.2f}")

elapsed_cpu = time.process_time() - start
print(f"\nCPU time: {elapsed_cpu:.2f} s")

"""SVC"""

import time
import numpy as np
import pandas as pd
import joblib

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import f1_score, precision_recall_curve
import tensorflow as tf

# -----------------------------
# Reproducibility
# -----------------------------
GLOBAL_SEED = 42
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

# -----------------------------
# Load and preprocess the data
# -----------------------------
data = pd.read_csv('/kaggle/input/personality-datasets1/MSAPersonality_processed_final.csv')
data.dropna(inplace=True)
print("Data shape:", data.shape)

# Load the saved BERT embeddings
embeddings = joblib.load('/kaggle/input/personality-datasets1/bert_embeddings_Morcoo_arabic.pkl')
X_all = np.array(embeddings, dtype=np.float32)

traits = ['E', 'N', 'A', 'C', 'O']
y_all = data[traits].to_numpy(dtype=np.int32)

num_tasks = y_all.shape[1]

# -----------------------------
# ONE split: 70/20/10
# -----------------------------
# 1) Split off TEST = 10%
X_train_val, X_test, y_train_val, y_test = train_test_split(
    X_all, y_all,
    test_size=0.10,
    random_state=GLOBAL_SEED,
    shuffle=True
)

# 2) VAL = 20% of full => 20/90 = 2/9 of train_val
X_train, X_val, y_train, y_val = train_test_split(
    X_train_val, y_train_val,
    test_size=(2/9),
    random_state=GLOBAL_SEED,
    shuffle=True
)

print(f"Full:  {len(X_all)}")
print(f"Train: {len(X_train)} ({len(X_train)/len(X_all)*100:.2f}%)")
print(f"Val:   {len(X_val)} ({len(X_val)/len(X_all)*100:.2f}%)")
print(f"Test:  {len(X_test)} ({len(X_test)/len(X_all)*100:.2f}%)")

# -----------------------------
# Per-label threshold tuning (safe)
# -----------------------------
def best_thresholds(y_true, y_prob):
    thresholds = np.zeros(y_true.shape[1], dtype=np.float32)
    for i in range(y_true.shape[1]):
        yt = y_true[:, i].astype(int)
        yp = y_prob[:, i].astype(float)

        # If only one class in validation split, PR curve undefined
        if len(np.unique(yt)) < 2:
            thresholds[i] = 0.5
            continue

        p, r, th = precision_recall_curve(yt, yp)
        if th.size == 0:
            thresholds[i] = 0.5
            continue

        f1 = 2 * p[:-1] * r[:-1] / (p[:-1] + r[:-1] + 1e-12)
        thresholds[i] = th[np.nanargmax(f1)]
    return thresholds

# -----------------------------
# SVC Expert
# -----------------------------
class SVCExpert:
    def __init__(self, C=50, kernel='linear', degree=2, gamma='scale',
                 tol=0.0001, class_weight=None, random_state=42, max_iter=-1):
        self.model = SVC(
            C=C,
            kernel=kernel,
            degree=degree,
            gamma=gamma,
            tol=tol,
            class_weight=class_weight,
            random_state=random_state,
            max_iter=max_iter,
            probability=True
        )

    def train(self, X_train, y_train_1d):
        self.model.fit(X_train, y_train_1d)

    def predict_proba_pos(self, X):
        proba = self.model.predict_proba(X)
        # If only one class present (rare but possible), handle safely
        if proba.shape[1] == 1:
            cls = self.model.classes_[0]
            return np.ones((X.shape[0],), dtype=np.float32) if cls == 1 else np.zeros((X.shape[0],), dtype=np.float32)
        return proba[:, 1].astype(np.float32)

# -----------------------------
# MGMOE (gates not trained; random)
# -----------------------------
class MultiGateMixtureOfExperts:
    """
    Same behavior as your previous MGMOE scripts:
    - Experts are trained (but see note below).
    - Gates are random and NOT trained (no optimizer/fit), so mixtures are random.
    """
    def __init__(self, num_tasks: int, input_dim: int, num_experts: int = 3, seed: int = 42):
        self.num_tasks = num_tasks
        self.num_experts = num_experts

        self.experts = [SVCExpert(random_state=seed) for _ in range(num_experts)]
        self.gates = [
            tf.Variable(tf.random.uniform([input_dim, num_experts], seed=seed), trainable=True)
            for _ in range(num_tasks)
        ]

    def train_experts(self, X_train, y_train):
        # WARNING: trains expert i on task i (works best when num_experts == num_tasks)
        # Keeping your original behavior.
        for i in range(self.num_experts):
            self.experts[i].train(X_train, y_train[:, i])

    def predict(self, X):
        out_experts = np.stack(
            [expert.predict_proba_pos(X) for expert in self.experts],
            axis=-1
        )  # (n, E)

        out_tasks = []
        X_tf = tf.convert_to_tensor(X, dtype=tf.float32)

        for gate in self.gates:
            gate_scores = tf.nn.softmax(tf.matmul(X_tf, gate), axis=-1).numpy().astype(np.float32)  # (n, E)
            task_output = np.sum(out_experts * gate_scores, axis=-1).astype(np.float32)             # (n,)
            out_tasks.append(task_output)

        return np.stack(out_tasks, axis=-1).astype(np.float32)  # (n, T)

# -----------------------------
# Train once (ONE run)
# -----------------------------
start = time.process_time()

# Fresh seeds
np.random.seed(GLOBAL_SEED)
tf.random.set_seed(GLOBAL_SEED)

model = MultiGateMixtureOfExperts(
    num_tasks=num_tasks,
    input_dim=X_train.shape[1],
    num_experts=3,
    seed=GLOBAL_SEED
)
model.train_experts(X_train, y_train)

# -----------------------------
# Threshold tuning on VAL
# -----------------------------
y_val_prob = model.predict(X_val)
thr = best_thresholds(y_val, y_val_prob)
print("Per-label thresholds:", dict(zip(traits, np.round(thr, 4))))

# -----------------------------
# Evaluate on TEST
# -----------------------------
y_test_prob = model.predict(X_test)

# Use tuned thresholds:
y_pred_labels = (y_test_prob >= 0.4).astype(np.int32)

# If you want fixed threshold 0.5 instead, use:
# y_pred_labels = (y_test_prob >= 0.5).astype(np.int32)

f1_micro = f1_score(y_test, y_pred_labels, average='micro', zero_division=0) * 100
f1_macro = f1_score(y_test, y_pred_labels, average='macro', zero_division=0) * 100

print("\n================ FINAL TEST RESULTS ================")
print(f"F1-micro: {f1_micro:.2f}")
print(f"F1-macro: {f1_macro:.2f}")

for i, name in enumerate(traits):
    f1_i = f1_score(y_test[:, i], y_pred_labels[:, i], zero_division=0) * 100
    print(f"  Task {name} - F1: {f1_i:.2f}")

elapsed_cpu = time.process_time() - start
print(f"\nCPU time: {elapsed_cpu:.2f} s")